{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import copy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solves quadratic programming problem of type\n",
    "# minimize 1/2 * x.T * G * x + a.T * x\n",
    "# subject to C * x >= b\n",
    "# Pass G - NxN; a - 1xN; C - MxN; b - 1xM\n",
    "# return - 1xN\n",
    "def solve_qp(G, a, C, b):\n",
    "    x0 = np.random.randn(len(G))\n",
    "\n",
    "    def loss(x, sign=1.):\n",
    "        return sign * (0.5 * np.dot(x.T, np.dot(G, x)) + np.dot(a, x))\n",
    "\n",
    "    def jac(x, sign=1.):\n",
    "        return sign * (np.dot(x.T, G) + a)\n",
    "\n",
    "    cons = {\n",
    "        'type': 'ineq',\n",
    "        'fun': lambda x: np.dot(C, x) - b,\n",
    "        'jac': lambda x: C\n",
    "    }\n",
    "\n",
    "    opt = {'disp': False}\n",
    "\n",
    "    return scipy.optimize.minimize(\n",
    "        loss, x0, jac=jac, constraints=cons, method='SLSQP', options=opt).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def target_function(x):\n",
    "    if len(x) > 2:\n",
    "        x = x[1:]\n",
    "    return np.sign(x[1] - x[0] + 0.25 * np.sin(np.pi * x[0]))\n",
    "\n",
    "\n",
    "# returns X Nxd+1 and Y 1xN\n",
    "def generate_points(target, n_points, r_dimension, bounds, bias=False):\n",
    "    X = np.random.uniform(bounds[0], bounds[1], (n_points, r_dimension))\n",
    "    Y = [target(i) for i in X]\n",
    "    if bias == True:\n",
    "        X = np.hstack((np.ones((n_points, 1)), X))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def kernel_rbf(gamma, x1, x2):\n",
    "    return np.exp(-gamma * np.linalg.norm(np.subtract(x1, x2))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hard_svm:\n",
    "    def __init__(self, X, Y, X_test, Y_test, kernel=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.kernel = kernel\n",
    "    \n",
    "    def test_e_out(self):\n",
    "        errors = 0\n",
    "        for i in range(len(self.X_test)):\n",
    "            answer = np.sign(self.query(self.X_test[i]))\n",
    "            if answer != self.Y_test[i]:\n",
    "                errors+=1\n",
    "        self.e_out = errors / len(self.X_test)\n",
    "    \n",
    "    def test_e_in(self):\n",
    "        errors = 0\n",
    "        for i in range(len(self.X)):\n",
    "            answer = np.sign(self.query(self.X[i]))\n",
    "            if answer != self.Y[i]:\n",
    "                errors += 1\n",
    "        self.e_in = errors / len(self.X)\n",
    "\n",
    "    def train(self):\n",
    "        G = self.construct_G()\n",
    "        a = self.construct_a()\n",
    "        C = self.construct_C()\n",
    "        b = self.construct_b()\n",
    "\n",
    "        self.alphas = np.around(solve_qp(G, np.negative(a), C, b), 9)\n",
    "        self.alphas = self.make_dense_dict(self.alphas)\n",
    "\n",
    "        if self.kernel == None:\n",
    "            self.construct_weights()\n",
    "        self.construct_bias()\n",
    "\n",
    "    def query(self, x):\n",
    "        if self.kernel == None:\n",
    "            return np.dot(self.w, x) + self.b\n",
    "        else:\n",
    "            sum_ = 0.\n",
    "            for key, value in self.alphas.items():\n",
    "                sum_ += self.Y[key] * value * self.kernel(self.X[key], x)\n",
    "            return sum_ + self.b\n",
    "\n",
    "    def construct_bias(self):\n",
    "        self.b = 0.\n",
    "        if len(self.alphas) != 0:\n",
    "            support_idx = next(iter(self.alphas))\n",
    "            for key, value in self.alphas.items():\n",
    "                if self.kernel == None:\n",
    "                    self.b += self.Y[key] * value * np.dot(\n",
    "                        self.X[key], self.X[support_idx])\n",
    "                else:\n",
    "                    self.b += self.Y[key] * value * self.kernel(\n",
    "                        self.X[key], self.X[support_idx])\n",
    "            self.b = self.Y[support_idx] - self.b\n",
    "\n",
    "    def construct_weights(self):\n",
    "        self.w = 0.\n",
    "        for key, value in self.alphas.items():\n",
    "            self.w += self.Y[key] * value * self.X[key]\n",
    "\n",
    "    def make_dense_dict(self, array):\n",
    "        dense_dict = {}\n",
    "        for i in range(len(array)):\n",
    "            if array[i] != 0:\n",
    "                dense_dict[i] = array[i]\n",
    "        return dense_dict\n",
    "\n",
    "    def construct_G(self):\n",
    "        G = []\n",
    "        for i in range(len(self.Y)):\n",
    "            g_row = []\n",
    "            for j in range(len(self.Y)):\n",
    "                if self.kernel != None:\n",
    "                    g_row.append(self.Y[i] * self.Y[j] * self.kernel(\n",
    "                        self.X[i], self.X[j]))\n",
    "                else:\n",
    "                    g_row.append(\n",
    "                        self.Y[i] * self.Y[j] * np.dot(self.X[i], self.X[j]))\n",
    "            G.append(g_row)\n",
    "        G = np.reshape(G, (len(self.Y), len(self.Y)))\n",
    "        return G\n",
    "\n",
    "    def construct_a(self):\n",
    "        return np.ones(len(self.Y))\n",
    "\n",
    "    def construct_C(self):\n",
    "        C = [self.Y, np.negative(self.Y)]\n",
    "        C = np.append(C, np.eye(len(self.Y)))\n",
    "        C = np.reshape(C, (len(self.Y) + 2, -1))\n",
    "        return C\n",
    "\n",
    "    def construct_b(self):\n",
    "        return np.zeros(len(self.Y) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lloyds_algorithm:\n",
    "    # X - points, K - number of clusters\n",
    "    def __init__(self, X, K):\n",
    "        self.X = X\n",
    "        self.K = K\n",
    "        self.N = len(self.X)\n",
    "        \n",
    "    def lloyds_algorithm(self):\n",
    "        self.cluster_points = {i: [] for i in range(self.K)}\n",
    "        self.cluster_centers = np.random.uniform(-1, 1,\n",
    "                                                 (self.K, len(self.X[0]) - 1))\n",
    "        self.cluster_centers = np.hstack((np.ones((self.K, 1)),\n",
    "                                          self.cluster_centers))\n",
    "        old_norm = float('inf')\n",
    "        old_centers = np.zeros((self.K, len(self.X[0])))\n",
    "        new_norm = 0.\n",
    "        while np.fabs(new_norm - old_norm) >= 1e-9:\n",
    "            old_norm = new_norm\n",
    "            old_centers = copy.copy(self.cluster_centers)\n",
    "            if self.lloyds_algorithm_closest_points() == False:\n",
    "                return False\n",
    "            self.lloyds_algorithm_update_centers()\n",
    "            new_norm = np.linalg.norm(\n",
    "                np.subtract(self.cluster_centers, old_centers))\n",
    "        return True\n",
    "\n",
    "    def lloyds_algorithm_update_centers(self):\n",
    "        for cluster_idx in range(self.K):\n",
    "            median = [0] * len(self.X[0])\n",
    "            for x_idx in self.cluster_points[cluster_idx]:\n",
    "                median = np.add(self.X[x_idx], median)\n",
    "            median = np.divide(median, len(self.cluster_points[cluster_idx]))\n",
    "            self.cluster_centers[cluster_idx] = median\n",
    "\n",
    "    def lloyds_algorithm_closest_points(self):\n",
    "        self.clear_cluster_points()\n",
    "\n",
    "        for x_idx in range(self.N):\n",
    "            closest_dist = float('inf')\n",
    "            closest_idx = -1\n",
    "            for cluster_idx in range(self.K):\n",
    "                dist = np.linalg.norm(\n",
    "                    np.subtract(self.X[x_idx],\n",
    "                                self.cluster_centers[cluster_idx]))\n",
    "                if dist < closest_dist:\n",
    "                    closest_dist = dist\n",
    "                    closest_idx = cluster_idx\n",
    "            self.cluster_points[closest_idx].append(x_idx)\n",
    "        if self.count_nonzero_clusters() != self.K:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def clear_cluster_points(self):\n",
    "        self.cluster_points = {i: [] for i in range(self.K)}\n",
    "\n",
    "    def count_nonzero_clusters(self):\n",
    "        non_zero = 0\n",
    "        for key, value in self.cluster_points.items():\n",
    "            if len(value) != 0:\n",
    "                non_zero += 1\n",
    "        return non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_in = 0:  99.33333333333333 % of times\n"
     ]
    }
   ],
   "source": [
    "# 13\n",
    "tests = 300\n",
    "n_points = 100\n",
    "gamma = 1.5\n",
    "kernel = functools.partial(kernel_rbf, gamma)\n",
    "\n",
    "e_in_zero = 0\n",
    "for i in range(tests):\n",
    "    X, Y = generate_points(target_function, n_points, 2, [-1, 1], True)\n",
    "    svm_rbf = Hard_svm(X, Y,[],[], kernel)\n",
    "    svm_rbf.train()\n",
    "    svm_rbf.test_e_in()\n",
    "    if svm_rbf.e_in == 0:\n",
    "        e_in_zero+=1\n",
    "print('E_in = 0: ',e_in_zero / tests * 100,'% of times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regular_form_rbf:\n",
    "    def __init__(self, X, Y, X_test, Y_test, gamma, K):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_test =X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.gamma = gamma\n",
    "        self.K = K\n",
    "        self.N = len(self.X)\n",
    "        self.lloyd = Lloyds_algorithm(self.X, self.K)\n",
    "\n",
    "    def feature_transform_point(self, x):\n",
    "        z_row = [1]\n",
    "        for cluster_idx in range(self.K):\n",
    "            z_row.append(\n",
    "                self.feature_transform(x, self.cluster_centers[cluster_idx]))\n",
    "        return z_row\n",
    "\n",
    "    def feature_transform(self, x, mu):\n",
    "        return np.exp(-0.5 * np.power(\n",
    "            self.gamma * np.linalg.norm(np.subtract(x, mu)), 2))\n",
    "\n",
    "    def construct_feature_matrix(self, X):\n",
    "        Z = []\n",
    "        for x_idx in range(len(X)):\n",
    "            Z.append(self.feature_transform_point(X[x_idx]))\n",
    "        return np.reshape(Z, (len(X), -1))\n",
    "\n",
    "    def train(self):\n",
    "        if self.lloyd.lloyds_algorithm():\n",
    "            # Run Lloyd's algorithm to find clusters\n",
    "            self.cluster_centers = self.lloyd.cluster_centers\n",
    "            self.cluster_points = self.lloyd.cluster_points\n",
    "\n",
    "            # Run hard SVM to find weights and final hypothesis\n",
    "            self.Z = self.construct_feature_matrix(self.X)\n",
    "            self.Z_test = self.construct_feature_matrix(self.X_test)\n",
    "            self.hard_svm = Hard_svm(self.Z, self.Y, self.Z_test, self.Y_test)\n",
    "            self.hard_svm.train()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def query(self, x):\n",
    "        z = self.feature_transform_point(x)\n",
    "        return np.sign(self.hard_svm.query(z))\n",
    "\n",
    "    def test_e_in(self):\n",
    "        self.hard_svm.test_e_in()\n",
    "        self.e_in = self.hard_svm.e_in\n",
    "        \n",
    "    def test_e_out(self):\n",
    "        self.hard_svm.test_e_out()\n",
    "        self.e_out = self.hard_svm.e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_clusters(regular_rbf):\n",
    "    for idx in range(regular_rbf.K):\n",
    "        rgb = np.random.randint(0,256,3)/255\n",
    "        for x_idx in regular_rbf.cluster_points[idx]:\n",
    "            plt.plot(\n",
    "                regular_rbf.X[x_idx][1],\n",
    "                regular_rbf.X[x_idx][2],\n",
    "                color=tuple(rgb),\n",
    "                marker='.')\n",
    "        plt.plot(\n",
    "            regular_rbf.cluster_centers[idx][1],\n",
    "            regular_rbf.cluster_centers[idx][2],\n",
    "            color=tuple(rgb),\n",
    "            marker='*',\n",
    "            markersize=10,\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K:  9  and Gamma:  1.5  over  200  runs\n",
      "Regular RBF average E_in:  0.05499999999999997\n",
      "Regular RBF average E_out:  0.07907500000000002\n",
      "Kernel hard SVM average E_in:  0.0\n",
      "Kernel hard SVM average E_out:  0.03122499999999999\n",
      "Kernel hard SVM had better E_out that resular RBF:  80.5 % of times\n",
      "\n",
      "\n",
      "Results for K:  12  and Gamma:  1.5  over  200  runs\n",
      "Regular RBF average E_in:  0.06289999999999994\n",
      "Regular RBF average E_out:  0.08598499999999999\n",
      "Kernel hard SVM average E_in:  0.0\n",
      "Kernel hard SVM average E_out:  0.03214999999999999\n",
      "Kernel hard SVM had better E_out that resular RBF:  75.5 % of times\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 14, 15, 16\n",
    "tests = 200\n",
    "n_points = 100\n",
    "n_test_points = 1000\n",
    "gamma = 1.5\n",
    "K = [9,12]\n",
    "kernel = functools.partial(kernel_rbf, gamma)\n",
    "\n",
    "for k in K:\n",
    "    regular_rbf_total_e_in = 0.\n",
    "    regular_rbf_total_e_out = 0.\n",
    "    svm_rbf_total_e_in = 0.\n",
    "    svm_rbf_total_e_out = 0.\n",
    "    n_svm_rbf_e_out_better = 0\n",
    "    for i in range(tests):\n",
    "        res = False\n",
    "        X_test, Y_test = generate_points(target_function, n_test_points, 2,\n",
    "                                         [-1, 1], True)\n",
    "        while res == False:\n",
    "            X, Y = generate_points(target_function, n_points, 2, [-1, 1], True)\n",
    "            regular_rbf = Regular_form_rbf(X, Y, X_test, Y_test, gamma, k)\n",
    "            res = regular_rbf.train()\n",
    "        regular_rbf.test_e_in()\n",
    "        regular_rbf.test_e_out()\n",
    "\n",
    "        svm_rbf_curr_e_in = 100\n",
    "        while(svm_rbf_curr_e_in!=0):\n",
    "            svm_rbf = Hard_svm(X, Y, X_test, Y_test, kernel)\n",
    "            svm_rbf.train()\n",
    "            svm_rbf.test_e_in()\n",
    "            svm_rbf_curr_e_in = svm_rbf.e_in\n",
    "        svm_rbf.test_e_out()\n",
    "\n",
    "        if svm_rbf.e_out < regular_rbf.e_out:\n",
    "            n_svm_rbf_e_out_better += 1\n",
    "\n",
    "        regular_rbf_total_e_in += regular_rbf.e_in\n",
    "        regular_rbf_total_e_out += regular_rbf.e_out\n",
    "        svm_rbf_total_e_in += svm_rbf.e_in\n",
    "        svm_rbf_total_e_out += svm_rbf.e_out\n",
    "\n",
    "    print('Results for K: ', k, ' and Gamma: ', gamma, ' over ', tests, ' runs')\n",
    "    print('Regular RBF average E_in: ', regular_rbf_total_e_in / tests)\n",
    "    print('Regular RBF average E_out: ', regular_rbf_total_e_out / tests)\n",
    "\n",
    "    print('Kernel hard SVM average E_in: ', svm_rbf_total_e_in / tests)\n",
    "    print('Kernel hard SVM average E_out: ', svm_rbf_total_e_out / tests)\n",
    "\n",
    "    print('Kernel hard SVM had better E_out that resular RBF: ',\n",
    "          n_svm_rbf_e_out_better / tests * 100, '% of times')\n",
    "    print('\\n')\n",
    "    \n",
    "# plot_clusters(regular_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K:  9  and Gamma:  1.5  over  200  runs\n",
      "Regular RBF average E_in:  0.0846\n",
      "Regular RBF average E_out:  0.10505000000000005\n",
      "\n",
      "\n",
      "Results for K:  9  and Gamma:  2  over  200  runs\n",
      "Regular RBF average E_in:  0.0554\n",
      "Regular RBF average E_out:  0.08231999999999993\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 17\n",
    "tests = 200\n",
    "n_points = 100\n",
    "n_test_points = 1000\n",
    "gamma = [1.5, 2]\n",
    "K = 9\n",
    "\n",
    "for g in gamma:\n",
    "    regular_rbf_total_e_in = 0.\n",
    "    regular_rbf_total_e_out = 0.\n",
    "    for i in range(tests):\n",
    "        res = False\n",
    "        X_test, Y_test = generate_points(target_function, n_test_points, 2,\n",
    "                                         [-1, 1], True)\n",
    "        while res == False:\n",
    "            X, Y = generate_points(target_function, n_points, 2, [-1, 1], True)\n",
    "            regular_rbf = Regular_form_rbf(X, Y, X_test, Y_test, g, K)\n",
    "            res = regular_rbf.train()\n",
    "        regular_rbf.test_e_in()\n",
    "        regular_rbf.test_e_out()\n",
    "        regular_rbf_total_e_in += regular_rbf.e_in\n",
    "        regular_rbf_total_e_out += regular_rbf.e_out\n",
    "    print('Results for K: ', K, ' and Gamma: ', g, ' over ', tests, ' runs')\n",
    "    print('Regular RBF average E_in: ', regular_rbf_total_e_in / tests)\n",
    "    print('Regular RBF average E_out: ', regular_rbf_total_e_out / tests)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K:  9  and Gamma:  1.5  over  200  runs\n",
      "Regular RBF acieved E_in=0.0 in  70.0 % of the times\n"
     ]
    }
   ],
   "source": [
    "# 18\n",
    "tests = 200\n",
    "n_points = 100\n",
    "gamma = 1.5\n",
    "K = 9\n",
    "\n",
    "e_in_zero = 0\n",
    "regular_rbf = 0.\n",
    "for i in range(tests):\n",
    "    res = False\n",
    "    while res == False:\n",
    "        X, Y = generate_points(target_function, n_points, 2, [-1, 1], True)\n",
    "        regular_rbf = Regular_form_rbf(X, Y, X_test, Y_test, g, K)\n",
    "        res = regular_rbf.train()\n",
    "    regular_rbf.test_e_in()\n",
    "    if regular_rbf.e_in == 0.:\n",
    "        e_in_zero += 1\n",
    "print('Results for K: ', K, ' and Gamma: ', gamma, ' over ', tests, ' runs')\n",
    "print('Regular RBF acieved E_in=0.0 in ', e_in_zero / tests * 100,\n",
    "      '% of the times')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
